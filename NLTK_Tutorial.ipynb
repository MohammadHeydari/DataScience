{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohammadHeydari/DataScience/blob/master/NLTK_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT8Y_FSN1EeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This repo summarizes text preprocessing and covers \n",
        "#the NLTK steps including Tokenization, Stemming, Lemmatization, \n",
        "#POS tagging, Named entity recognition and Chunking."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4NdbYKGJ4ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import necessary labs for sure."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1nmTliv1gGl",
        "colab_type": "code",
        "outputId": "7bcd3304-4b10-4a2e-d11f-37ed5a899de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "import os\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk import ne_chunk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        " \n",
        "\n",
        "#NER\n",
        "text = \"In today’s scenario, one way of people’s success identified by how they are communicating and sharing information to others. That’s where the concepts of language come into picture. However, there are many languages in the world. Each has many standards and alphabets, and the combination of these words arranged meaningfully resulted in the formation of a sentence. Each language has its own rules while developing these sentences and these set of rules are also known as grammar.\"\n",
        "\n",
        "#tokenize and POS tagging before doing chunk\n",
        "token = word_tokenize(text)\n",
        "token"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " 'today',\n",
              " '’',\n",
              " 's',\n",
              " 'scenario',\n",
              " ',',\n",
              " 'one',\n",
              " 'way',\n",
              " 'of',\n",
              " 'people',\n",
              " '’',\n",
              " 's',\n",
              " 'success',\n",
              " 'identified',\n",
              " 'by',\n",
              " 'how',\n",
              " 'they',\n",
              " 'are',\n",
              " 'communicating',\n",
              " 'and',\n",
              " 'sharing',\n",
              " 'information',\n",
              " 'to',\n",
              " 'others',\n",
              " '.',\n",
              " 'That',\n",
              " '’',\n",
              " 's',\n",
              " 'where',\n",
              " 'the',\n",
              " 'concepts',\n",
              " 'of',\n",
              " 'language',\n",
              " 'come',\n",
              " 'into',\n",
              " 'picture',\n",
              " '.',\n",
              " 'However',\n",
              " ',',\n",
              " 'there',\n",
              " 'are',\n",
              " 'many',\n",
              " 'languages',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " '.',\n",
              " 'Each',\n",
              " 'has',\n",
              " 'many',\n",
              " 'standards',\n",
              " 'and',\n",
              " 'alphabets',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'combination',\n",
              " 'of',\n",
              " 'these',\n",
              " 'words',\n",
              " 'arranged',\n",
              " 'meaningfully',\n",
              " 'resulted',\n",
              " 'in',\n",
              " 'the',\n",
              " 'formation',\n",
              " 'of',\n",
              " 'a',\n",
              " 'sentence',\n",
              " '.',\n",
              " 'Each',\n",
              " 'language',\n",
              " 'has',\n",
              " 'its',\n",
              " 'own',\n",
              " 'rules',\n",
              " 'while',\n",
              " 'developing',\n",
              " 'these',\n",
              " 'sentences',\n",
              " 'and',\n",
              " 'these',\n",
              " 'set',\n",
              " 'of',\n",
              " 'rules',\n",
              " 'are',\n",
              " 'also',\n",
              " 'known',\n",
              " 'as',\n",
              " 'grammar',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTSLkeFi3QSx",
        "colab_type": "code",
        "outputId": "cb915c98-5671-4ceb-8273-b378b675dd3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# finding the frequency distinct in the tokens\n",
        "# Importing FreqDist library from nltk and passing token into FreqDist\n",
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist(token)\n",
        "fdist\n",
        "\n",
        "#frequency\n",
        "from nltk.probability import FreqDist\n",
        "freqdist = FreqDist(token)\n",
        "freqdist"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({',': 3,\n",
              "          '.': 5,\n",
              "          'Each': 2,\n",
              "          'However': 1,\n",
              "          'In': 1,\n",
              "          'That': 1,\n",
              "          'a': 1,\n",
              "          'alphabets': 1,\n",
              "          'also': 1,\n",
              "          'and': 4,\n",
              "          'are': 3,\n",
              "          'arranged': 1,\n",
              "          'as': 1,\n",
              "          'by': 1,\n",
              "          'combination': 1,\n",
              "          'come': 1,\n",
              "          'communicating': 1,\n",
              "          'concepts': 1,\n",
              "          'developing': 1,\n",
              "          'formation': 1,\n",
              "          'grammar': 1,\n",
              "          'has': 2,\n",
              "          'how': 1,\n",
              "          'identified': 1,\n",
              "          'in': 2,\n",
              "          'information': 1,\n",
              "          'into': 1,\n",
              "          'its': 1,\n",
              "          'known': 1,\n",
              "          'language': 2,\n",
              "          'languages': 1,\n",
              "          'many': 2,\n",
              "          'meaningfully': 1,\n",
              "          'of': 5,\n",
              "          'one': 1,\n",
              "          'others': 1,\n",
              "          'own': 1,\n",
              "          'people': 1,\n",
              "          'picture': 1,\n",
              "          'resulted': 1,\n",
              "          'rules': 2,\n",
              "          's': 3,\n",
              "          'scenario': 1,\n",
              "          'sentence': 1,\n",
              "          'sentences': 1,\n",
              "          'set': 1,\n",
              "          'sharing': 1,\n",
              "          'standards': 1,\n",
              "          'success': 1,\n",
              "          'the': 4,\n",
              "          'there': 1,\n",
              "          'these': 3,\n",
              "          'they': 1,\n",
              "          'to': 1,\n",
              "          'today': 1,\n",
              "          'way': 1,\n",
              "          'where': 1,\n",
              "          'while': 1,\n",
              "          'words': 1,\n",
              "          'world': 1,\n",
              "          '’': 3})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTayrciI33BG",
        "colab_type": "code",
        "outputId": "96960217-9074-4b31-f8c2-23d5055b9943",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "source": [
        "#frequency of top 10 words \n",
        "freq_dist_top10 = freqdist.most_common(10)\n",
        "freq_dist_top10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('of', 5),\n",
              " ('.', 5),\n",
              " ('and', 4),\n",
              " ('the', 4),\n",
              " ('’', 3),\n",
              " ('s', 3),\n",
              " (',', 3),\n",
              " ('are', 3),\n",
              " ('these', 3),\n",
              " ('language', 2)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EH5Zek565EH7",
        "colab_type": "code",
        "outputId": "90cc38af-c295-4f0e-d3c2-45aeda766aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#stemming\n",
        "# Importing Porterstemmer from nltk library\n",
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()\n",
        "pst.stem(\"doing\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'do'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBp2nyGB5aSU",
        "colab_type": "code",
        "outputId": "cc216a6d-8b7a-44d0-cc9f-7e209ab317e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "#stem in list by loop\n",
        "#list of verbs to be stemmed\n",
        "verb = [\"looking\", \"Doing\",\"working\", \"caring\", \"dareing\"]\n",
        "#a loop to access loop elements of lists\n",
        "for word in verb:\n",
        "  #stemming the verbs in list by accessing main pointer of loop to the list which is word\n",
        "  print(word+ \":\" + pst.stem(word))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "looking:look\n",
            "Doing:do\n",
            "working:work\n",
            "caring:care\n",
            "dareing:dare\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntn3Nmzl70mz",
        "colab_type": "code",
        "outputId": "67d3fdcc-9bdc-4e81-ab81-2303e69db750",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        " #lancaster stemmer\n",
        " from nltk.stem import LancasterStemmer\n",
        " lancaster = LancasterStemmer()\n",
        " for word in verb:\n",
        "   print(word+ \":\" +lancaster.stem(word))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "looking:look\n",
            "Doing:doing\n",
            "working:work\n",
            "caring:car\n",
            "dareing:dar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3MURgyd92Px",
        "colab_type": "code",
        "outputId": "cd656287-1d45-4dce-e558-2f9db6bedf39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "#lematize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer() \n",
        " \n",
        "print(\"dogs :\", lemmatizer.lemmatize(\"dogs\")) \n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))\n",
        "print(\"outstanding\", lemmatizer.lemmatize(\"outstanding\"))\n",
        "print(\"magnificent\", lemmatizer.lemmatize(\"magnificent\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dogs : dog\n",
            "corpora : corpus\n",
            "outstanding outstanding\n",
            "magnificent magnificent\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BShuqiGMD29A",
        "colab_type": "code",
        "outputId": "1d97140d-b418-4ccf-e043-f53afae6ffc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "#stopwords\n",
        "# importing stopwors from nltk library\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stopwords_set = set(stopwords.words('english'))\n",
        "text = \"In today’s scenario, one way of people’s success identified by how they are communicating and sharing information to others. That’s where the concepts of language come into picture. However, there are many languages in the world. Each has many standards and alphabets, and the combination of these words arranged meaningfully resulted in the formation of a sentence. Each language has its own rules while developing these sentences and these set of rules are also known as grammar.\"\n",
        "tokenized_text = word_tokenize(text.lower())\n",
        "print(tokenized_text)\n",
        "print('---')\n",
        "#stopwords = [x for x in tokenized_text if x not in stopwords_set]\n",
        "stopwords = [x for x in tokenized_text if x not in stopwords_set]\n",
        "print(stopwords)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['in', 'today', '’', 's', 'scenario', ',', 'one', 'way', 'of', 'people', '’', 's', 'success', 'identified', 'by', 'how', 'they', 'are', 'communicating', 'and', 'sharing', 'information', 'to', 'others', '.', 'that', '’', 's', 'where', 'the', 'concepts', 'of', 'language', 'come', 'into', 'picture', '.', 'however', ',', 'there', 'are', 'many', 'languages', 'in', 'the', 'world', '.', 'each', 'has', 'many', 'standards', 'and', 'alphabets', ',', 'and', 'the', 'combination', 'of', 'these', 'words', 'arranged', 'meaningfully', 'resulted', 'in', 'the', 'formation', 'of', 'a', 'sentence', '.', 'each', 'language', 'has', 'its', 'own', 'rules', 'while', 'developing', 'these', 'sentences', 'and', 'these', 'set', 'of', 'rules', 'are', 'also', 'known', 'as', 'grammar', '.']\n",
            "---\n",
            "['today', '’', 'scenario', ',', 'one', 'way', 'people', '’', 'success', 'identified', 'communicating', 'sharing', 'information', 'others', '.', '’', 'concepts', 'language', 'come', 'picture', '.', 'however', ',', 'many', 'languages', 'world', '.', 'many', 'standards', 'alphabets', ',', 'combination', 'words', 'arranged', 'meaningfully', 'resulted', 'formation', 'sentence', '.', 'language', 'rules', 'developing', 'sentences', 'set', 'rules', 'also', 'known', 'grammar', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Nm-LgQwF-oo",
        "colab_type": "code",
        "outputId": "ef9d8645-7a49-4513-9457-52c63bac1606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "#NER\n",
        "text1 = \"Mohammad Heydari is interested to do NLP projects in a high tech company like Google in United States of America in 2022\"\n",
        "from nltk import ne_chunk\n",
        "#tokenize and POS tagging before doing chunking\n",
        "token = word_tokenize(text1)\n",
        "tags = nltk.pos_tag(token)\n",
        "chunk = ne_chunk(tags)\n",
        "chunk"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TclError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTclError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/tree.py\u001b[0m in \u001b[0;36m_repr_png_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfind_binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m         \u001b[0m_canvas_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCanvasFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0mwidget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_to_treesegment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0m_canvas_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_widget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/nltk/draw/util.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, parent, **kw)\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;31m# If no parent was given, set up a top-level window.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1653\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1654\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NLTK'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<Control-p>'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, screenName, baseName, className, useTk, sync, use)\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 \u001b[0mbaseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseName\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2022\u001b[0m         \u001b[0minteractive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2023\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tkinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreenName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minteractive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantobjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2024\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0museTk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2025\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loadtk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTclError\u001b[0m: no display name and no $DISPLAY environment variable"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tree('S', [Tree('PERSON', [('Mohammad', 'NNP')]), Tree('ORGANIZATION', [('Heydari', 'NNP')]), ('is', 'VBZ'), ('interested', 'JJ'), ('to', 'TO'), ('do', 'VB'), Tree('ORGANIZATION', [('NLP', 'NNP')]), ('projects', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('high', 'JJ'), ('tech', 'NN'), ('company', 'NN'), ('like', 'IN'), Tree('ORGANIZATION', [('Google', 'NNP')]), ('in', 'IN'), Tree('GPE', [('United', 'NNP'), ('States', 'NNPS')]), ('of', 'IN'), Tree('GPE', [('America', 'NNP')]), ('in', 'IN'), ('2022', 'CD')])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-Y81YF_JAIF",
        "colab_type": "code",
        "outputId": "73452205-1dcc-46d3-ec74-ccfe723616dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#group by chunking result by Regex\n",
        "\n",
        "text3 = \"we meet the great leader of tech\"\n",
        "token = word_tokenize(text3)\n",
        "tags = nltk.pos_tag(token)\n",
        "reg = \"NP: {<DT>?<JJ>*<NN>}\" \n",
        "regex = nltk.RegexpParser(reg)\n",
        "result = regex.parse(tags)\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S we/PRP meet/VBP (NP the/DT great/JJ leader/NN) of/IN (NP tech/NN))\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}